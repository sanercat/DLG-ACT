Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=50.0, layer_num=32, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([256]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=40.0, layer_num=60, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([10, 512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:27.031907
Attack - Iter-0: Rec_loss-0.3647.
Attack - Iter-1000: Rec_loss-0.0931.
Attack - Iter-2000: Rec_loss-0.0948.
Attack - Iter-3000: Rec_loss-0.0910.
Attack - Iter-4000: Rec_loss-0.0842.
Attack - Iter-5000: Rec_loss-0.0877.
Attack - Iter-6000: Rec_loss-0.0875.
Attack - Iter-7000: Rec_loss-0.0854.
Attack - Iter-8000: Rec_loss-0.0862.
Attack - Iter-9000: Rec_loss-0.0832.
Attack - Iter-9999: Rec_loss-0.0818.
PSNR 20.9225 SSIM 0.7095 LPIPS -0.0000
Tuesday, 29. October 2024 08:26PM
Finished computations with time: 0:02:36.081858
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=40.0, layer_num=61, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([10]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=40.0, layer_num=58, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:25.376285
Attack - Iter-0: Rec_loss-0.3440.
Attack - Iter-1000: Rec_loss-0.0553.
Attack - Iter-2000: Rec_loss-0.0498.
Attack - Iter-3000: Rec_loss-0.0328.
Attack - Iter-4000: Rec_loss-0.0306.
Attack - Iter-5000: Rec_loss-0.0358.
Attack - Iter-6000: Rec_loss-0.0374.
Attack - Iter-7000: Rec_loss-0.0309.
Attack - Iter-8000: Rec_loss-0.0223.
Attack - Iter-9000: Rec_loss-0.0177.
Attack - Iter-9999: Rec_loss-0.0167.
PSNR 24.5666 SSIM 0.8477 LPIPS -0.0000
Tuesday, 29. October 2024 08:33PM
Finished computations with time: 0:02:33.461665
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=40.0, layer_num=59, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:24.412059
Attack - Iter-0: Rec_loss-0.3440.
Attack - Iter-1000: Rec_loss-0.0546.
Attack - Iter-2000: Rec_loss-0.0396.
Attack - Iter-3000: Rec_loss-0.0669.
Attack - Iter-4000: Rec_loss-0.0354.
Attack - Iter-5000: Rec_loss-0.0344.
Attack - Iter-6000: Rec_loss-0.0290.
Attack - Iter-7000: Rec_loss-0.0366.
Attack - Iter-8000: Rec_loss-0.0470.
Attack - Iter-9000: Rec_loss-0.0393.
Attack - Iter-9999: Rec_loss-0.0417.
PSNR 22.8530 SSIM 0.7902 LPIPS -0.0000
Tuesday, 29. October 2024 08:37PM
Finished computations with time: 0:02:32.625799
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=40.0, layer_num=46, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:25.669102
Attack - Iter-0: Rec_loss-0.1169.
Attack - Iter-1000: Rec_loss-0.1355.
Attack - Iter-2000: Rec_loss-0.1378.
Attack - Iter-3000: Rec_loss-0.1414.
Attack - Iter-4000: Rec_loss-0.1365.
Attack - Iter-5000: Rec_loss-0.1295.
Attack - Iter-6000: Rec_loss-0.1284.
Attack - Iter-7000: Rec_loss-0.1279.
Attack - Iter-8000: Rec_loss-0.1266.
Attack - Iter-9000: Rec_loss-0.1275.
Attack - Iter-9999: Rec_loss-0.1276.
PSNR 7.4282 SSIM 0.1342 LPIPS -0.0000
Tuesday, 29. October 2024 08:40PM
Finished computations with time: 0:02:35.971359
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=40.0, layer_num=58, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:26.911750
Attack - Iter-0: Rec_loss-0.3440.
Attack - Iter-1000: Rec_loss-0.0553.
Attack - Iter-2000: Rec_loss-0.0498.
Attack - Iter-3000: Rec_loss-0.0328.
Attack - Iter-4000: Rec_loss-0.0306.
Attack - Iter-5000: Rec_loss-0.0358.
Attack - Iter-6000: Rec_loss-0.0374.
Attack - Iter-7000: Rec_loss-0.0309.
Attack - Iter-8000: Rec_loss-0.0223.
Attack - Iter-9000: Rec_loss-0.0177.
Attack - Iter-9999: Rec_loss-0.0167.
PSNR 24.5666 SSIM 0.8477 LPIPS -0.0000
Tuesday, 29. October 2024 08:54PM
Finished computations with time: 0:03:22.496317
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=40.0, layer_num=46, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:24.405668
Attack - Iter-0: Rec_loss-0.3440.
Attack - Iter-1000: Rec_loss-0.0559.
Attack - Iter-2000: Rec_loss-0.0483.
Attack - Iter-3000: Rec_loss-0.0415.
Attack - Iter-4000: Rec_loss-0.0436.
Attack - Iter-5000: Rec_loss-0.0211.
Attack - Iter-6000: Rec_loss-0.0347.
Attack - Iter-7000: Rec_loss-0.0216.
Attack - Iter-8000: Rec_loss-0.0293.
Attack - Iter-9000: Rec_loss-0.0347.
Attack - Iter-9999: Rec_loss-0.0240.
PSNR 25.4834 SSIM 0.8397 LPIPS -0.0000
Tuesday, 29. October 2024 08:57PM
Finished computations with time: 0:02:29.330723
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=40.0, layer_num=60, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([10, 512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:23.673631
Attack - Iter-0: Rec_loss-0.3647.
Attack - Iter-1000: Rec_loss-0.0931.
Attack - Iter-2000: Rec_loss-0.0948.
Attack - Iter-3000: Rec_loss-0.0910.
Attack - Iter-4000: Rec_loss-0.0842.
Attack - Iter-5000: Rec_loss-0.0877.
Attack - Iter-6000: Rec_loss-0.0875.
Attack - Iter-7000: Rec_loss-0.0854.
Attack - Iter-8000: Rec_loss-0.0862.
Attack - Iter-9000: Rec_loss-0.0832.
Attack - Iter-9999: Rec_loss-0.0818.
PSNR 20.9225 SSIM 0.7095 LPIPS -0.0000
Tuesday, 29. October 2024 09:06PM
Finished computations with time: 0:02:28.042444
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=30.0, layer_num=56, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:24.656413
Attack - Iter-0: Rec_loss-0.3440.
Attack - Iter-1000: Rec_loss-0.0427.
Attack - Iter-2000: Rec_loss-0.0536.
Attack - Iter-3000: Rec_loss-0.0559.
Attack - Iter-4000: Rec_loss-0.0386.
Attack - Iter-5000: Rec_loss-0.0536.
Attack - Iter-6000: Rec_loss-0.0326.
Attack - Iter-7000: Rec_loss-0.0311.
Attack - Iter-8000: Rec_loss-0.0363.
Attack - Iter-9000: Rec_loss-0.0512.
Attack - Iter-9999: Rec_loss-0.0351.
PSNR 24.4269 SSIM 0.7925 LPIPS -0.0000
Tuesday, 29. October 2024 09:10PM
Finished computations with time: 0:02:32.368914
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=40.0, layer_num=60, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([10, 512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:26.556164
Attack - Iter-0: Rec_loss-0.3647.
Attack - Iter-1000: Rec_loss-0.0931.
Attack - Iter-2000: Rec_loss-0.0948.
Attack - Iter-3000: Rec_loss-0.0910.
Attack - Iter-4000: Rec_loss-0.0842.
Attack - Iter-5000: Rec_loss-0.0877.
Attack - Iter-6000: Rec_loss-0.0875.
Attack - Iter-7000: Rec_loss-0.0854.
Attack - Iter-8000: Rec_loss-0.0862.
Attack - Iter-9000: Rec_loss-0.0832.
Attack - Iter-9999: Rec_loss-0.0818.
PSNR 20.9225 SSIM 0.7095 LPIPS -0.0000
Tuesday, 29. October 2024 09:20PM
Finished computations with time: 0:02:34.716385
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=40.0, layer_num=50, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:23.861371
Attack - Iter-0: Rec_loss-0.3440.
Attack - Iter-1000: Rec_loss-0.0558.
Attack - Iter-2000: Rec_loss-0.0587.
Attack - Iter-3000: Rec_loss-0.0441.
Attack - Iter-4000: Rec_loss-0.0377.
Attack - Iter-5000: Rec_loss-0.0461.
Attack - Iter-6000: Rec_loss-0.0310.
Attack - Iter-7000: Rec_loss-0.0392.
Attack - Iter-8000: Rec_loss-0.0301.
Attack - Iter-9000: Rec_loss-0.0293.
Attack - Iter-9999: Rec_loss-0.0311.
PSNR 24.0059 SSIM 0.8067 LPIPS -0.0000
Tuesday, 29. October 2024 09:24PM
Finished computations with time: 0:02:32.144843
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=50.0, layer_num=60, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([10, 512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:25.181926
Attack - Iter-0: Rec_loss-0.4180.
Attack - Iter-10: Rec_loss-0.2711.
Attack - Iter-20: Rec_loss-0.2623.
Attack - Iter-30: Rec_loss-0.2598.
Attack - Iter-40: Rec_loss-0.2339.
Attack - Iter-50: Rec_loss-0.2151.
Attack - Iter-60: Rec_loss-0.1896.
Attack - Iter-70: Rec_loss-0.1944.
Attack - Iter-80: Rec_loss-0.1880.
Attack - Iter-90: Rec_loss-0.1924.
Attack - Iter-100: Rec_loss-0.1827.
Attack - Iter-110: Rec_loss-0.1780.
Attack - Iter-120: Rec_loss-0.1639.
Attack - Iter-130: Rec_loss-0.1663.
Attack - Iter-140: Rec_loss-0.1579.
Attack - Iter-150: Rec_loss-0.1640.
Attack - Iter-160: Rec_loss-0.1579.
Attack - Iter-170: Rec_loss-0.1599.
Attack - Iter-180: Rec_loss-0.1565.
Attack - Iter-190: Rec_loss-0.1762.
Attack - Iter-200: Rec_loss-0.1618.
Attack - Iter-210: Rec_loss-0.1614.
Attack - Iter-220: Rec_loss-0.1637.
Attack - Iter-230: Rec_loss-0.1638.
Attack - Iter-240: Rec_loss-0.1642.
Attack - Iter-250: Rec_loss-0.1583.
Attack - Iter-260: Rec_loss-0.1656.
Attack - Iter-270: Rec_loss-0.1643.
Attack - Iter-280: Rec_loss-0.1656.
Attack - Iter-290: Rec_loss-0.1678.
Attack - Iter-300: Rec_loss-0.1709.
Attack - Iter-310: Rec_loss-0.1571.
Attack - Iter-320: Rec_loss-0.1608.
Attack - Iter-330: Rec_loss-0.1578.
Attack - Iter-340: Rec_loss-0.1655.
Attack - Iter-350: Rec_loss-0.1613.
Attack - Iter-360: Rec_loss-0.1597.
Attack - Iter-370: Rec_loss-0.1659.
Attack - Iter-380: Rec_loss-0.1530.
Attack - Iter-390: Rec_loss-0.1630.
Attack - Iter-400: Rec_loss-0.1708.
Attack - Iter-410: Rec_loss-0.1587.
Attack - Iter-420: Rec_loss-0.1724.
Attack - Iter-430: Rec_loss-0.1653.
Attack - Iter-440: Rec_loss-0.1675.
Attack - Iter-450: Rec_loss-0.1566.
Attack - Iter-460: Rec_loss-0.1717.
Attack - Iter-470: Rec_loss-0.1574.
Attack - Iter-480: Rec_loss-0.1579.
Attack - Iter-490: Rec_loss-0.1585.
Attack - Iter-500: Rec_loss-0.1616.
Attack - Iter-510: Rec_loss-0.1628.
Attack - Iter-520: Rec_loss-0.1552.
Attack - Iter-530: Rec_loss-0.1518.
Attack - Iter-540: Rec_loss-0.1529.
Attack - Iter-550: Rec_loss-0.1722.
Attack - Iter-560: Rec_loss-0.1639.
Attack - Iter-570: Rec_loss-0.1570.
Attack - Iter-580: Rec_loss-0.1702.
Attack - Iter-590: Rec_loss-0.1712.
Attack - Iter-600: Rec_loss-0.1542.
Attack - Iter-610: Rec_loss-0.1560.
Attack - Iter-620: Rec_loss-0.1527.
Attack - Iter-630: Rec_loss-0.1692.
Attack - Iter-640: Rec_loss-0.1667.
Attack - Iter-650: Rec_loss-0.1526.
Attack - Iter-660: Rec_loss-0.1576.
Attack - Iter-670: Rec_loss-0.1650.
Attack - Iter-680: Rec_loss-0.1607.
Attack - Iter-690: Rec_loss-0.1548.
Attack - Iter-700: Rec_loss-0.1577.
Attack - Iter-710: Rec_loss-0.1574.
Attack - Iter-720: Rec_loss-0.1646.
Attack - Iter-730: Rec_loss-0.1660.
Attack - Iter-740: Rec_loss-0.1686.
Attack - Iter-750: Rec_loss-0.1572.
Attack - Iter-760: Rec_loss-0.1626.
Attack - Iter-770: Rec_loss-0.1662.
Attack - Iter-780: Rec_loss-0.1677.
Attack - Iter-790: Rec_loss-0.1668.
Attack - Iter-800: Rec_loss-0.1673.
Attack - Iter-810: Rec_loss-0.1607.
Attack - Iter-820: Rec_loss-0.1714.
Attack - Iter-830: Rec_loss-0.1659.
Attack - Iter-840: Rec_loss-0.1691.
Attack - Iter-850: Rec_loss-0.1699.
Attack - Iter-860: Rec_loss-0.1634.
Attack - Iter-870: Rec_loss-0.1641.
Attack - Iter-880: Rec_loss-0.1504.
Attack - Iter-890: Rec_loss-0.1536.
Attack - Iter-900: Rec_loss-0.1634.
Attack - Iter-910: Rec_loss-0.1592.
Attack - Iter-920: Rec_loss-0.1685.
Attack - Iter-930: Rec_loss-0.1669.
Attack - Iter-940: Rec_loss-0.1622.
Attack - Iter-950: Rec_loss-0.1662.
Attack - Iter-960: Rec_loss-0.1569.
Attack - Iter-970: Rec_loss-0.1692.
Attack - Iter-980: Rec_loss-0.1604.
Attack - Iter-990: Rec_loss-0.1478.
Attack - Iter-1000: Rec_loss-0.1624.
Attack - Iter-1010: Rec_loss-0.1574.
Attack - Iter-1020: Rec_loss-0.1714.
Attack - Iter-1030: Rec_loss-0.1622.
Attack - Iter-1040: Rec_loss-0.1648.
Attack - Iter-1050: Rec_loss-0.1670.
Attack - Iter-1060: Rec_loss-0.1480.
Attack - Iter-1070: Rec_loss-0.1592.
Attack - Iter-1080: Rec_loss-0.1487.
Attack - Iter-1090: Rec_loss-0.1624.
Attack - Iter-1100: Rec_loss-0.1504.
Attack - Iter-1110: Rec_loss-0.1596.
Attack - Iter-1120: Rec_loss-0.1616.
Attack - Iter-1130: Rec_loss-0.1571.
Attack - Iter-1140: Rec_loss-0.1528.
Attack - Iter-1150: Rec_loss-0.1613.
Attack - Iter-1160: Rec_loss-0.1457.
Attack - Iter-1170: Rec_loss-0.1528.
Attack - Iter-1180: Rec_loss-0.1416.
Attack - Iter-1190: Rec_loss-0.1518.
Attack - Iter-1200: Rec_loss-0.1542.
Attack - Iter-1210: Rec_loss-0.1524.
Attack - Iter-1220: Rec_loss-0.1482.
Attack - Iter-1230: Rec_loss-0.1509.
Attack - Iter-1240: Rec_loss-0.1625.
Attack - Iter-1250: Rec_loss-0.1422.
Attack - Iter-1260: Rec_loss-0.1531.
Attack - Iter-1270: Rec_loss-0.1491.
Attack - Iter-1280: Rec_loss-0.1525.
Attack - Iter-1290: Rec_loss-0.1502.
Attack - Iter-1300: Rec_loss-0.1507.
Attack - Iter-1310: Rec_loss-0.1546.
Attack - Iter-1320: Rec_loss-0.1515.
Attack - Iter-1330: Rec_loss-0.1495.
Attack - Iter-1340: Rec_loss-0.1471.
Attack - Iter-1350: Rec_loss-0.1513.
Attack - Iter-1360: Rec_loss-0.1402.
Attack - Iter-1370: Rec_loss-0.1532.
Attack - Iter-1380: Rec_loss-0.1481.
Attack - Iter-1390: Rec_loss-0.1602.
Attack - Iter-1400: Rec_loss-0.1507.
Attack - Iter-1410: Rec_loss-0.1559.
Attack - Iter-1420: Rec_loss-0.1449.
Attack - Iter-1430: Rec_loss-0.1534.
Attack - Iter-1440: Rec_loss-0.1524.
Attack - Iter-1450: Rec_loss-0.1580.
Attack - Iter-1460: Rec_loss-0.1569.
Attack - Iter-1470: Rec_loss-0.1512.
Attack - Iter-1480: Rec_loss-0.1593.
Attack - Iter-1490: Rec_loss-0.1553.
Attack - Iter-1500: Rec_loss-0.1559.
Attack - Iter-1510: Rec_loss-0.1597.
Attack - Iter-1520: Rec_loss-0.1569.
Attack - Iter-1530: Rec_loss-0.1618.
Attack - Iter-1540: Rec_loss-0.1536.
Attack - Iter-1550: Rec_loss-0.1608.
Attack - Iter-1560: Rec_loss-0.1527.
Attack - Iter-1570: Rec_loss-0.1618.
Attack - Iter-1580: Rec_loss-0.1552.
Attack - Iter-1590: Rec_loss-0.1614.
Attack - Iter-1600: Rec_loss-0.1623.
Attack - Iter-1610: Rec_loss-0.1491.
Attack - Iter-1620: Rec_loss-0.1545.
Attack - Iter-1630: Rec_loss-0.1501.
Attack - Iter-1640: Rec_loss-0.1642.
Attack - Iter-1650: Rec_loss-0.1510.
Attack - Iter-1660: Rec_loss-0.1570.
Attack - Iter-1670: Rec_loss-0.1568.
Attack - Iter-1680: Rec_loss-0.1607.
Attack - Iter-1690: Rec_loss-0.1503.
Attack - Iter-1700: Rec_loss-0.1645.
Attack - Iter-1710: Rec_loss-0.1515.
Attack - Iter-1720: Rec_loss-0.1480.
Attack - Iter-1730: Rec_loss-0.1550.
Attack - Iter-1740: Rec_loss-0.1566.
Attack - Iter-1750: Rec_loss-0.1500.
Attack - Iter-1760: Rec_loss-0.1542.
Attack - Iter-1770: Rec_loss-0.1564.
Attack - Iter-1780: Rec_loss-0.1617.
Attack - Iter-1790: Rec_loss-0.1591.
Attack - Iter-1800: Rec_loss-0.1472.
Attack - Iter-1810: Rec_loss-0.1618.
Attack - Iter-1820: Rec_loss-0.1569.
Attack - Iter-1830: Rec_loss-0.1557.
Attack - Iter-1840: Rec_loss-0.1495.
Attack - Iter-1850: Rec_loss-0.1554.
Attack - Iter-1860: Rec_loss-0.1637.
Attack - Iter-1870: Rec_loss-0.1594.
Attack - Iter-1880: Rec_loss-0.1660.
Attack - Iter-1890: Rec_loss-0.1587.
Attack - Iter-1900: Rec_loss-0.1561.
Attack - Iter-1910: Rec_loss-0.1580.
Attack - Iter-1920: Rec_loss-0.1620.
Attack - Iter-1930: Rec_loss-0.1489.
Attack - Iter-1940: Rec_loss-0.1717.
Attack - Iter-1950: Rec_loss-0.1637.
Attack - Iter-1960: Rec_loss-0.1561.
Attack - Iter-1970: Rec_loss-0.1510.
Attack - Iter-1980: Rec_loss-0.1616.
Attack - Iter-1990: Rec_loss-0.1560.
Attack - Iter-2000: Rec_loss-0.1635.
Attack - Iter-2010: Rec_loss-0.1611.
Attack - Iter-2020: Rec_loss-0.1549.
Attack - Iter-2030: Rec_loss-0.1600.
Attack - Iter-2040: Rec_loss-0.1702.
Attack - Iter-2050: Rec_loss-0.1605.
Attack - Iter-2060: Rec_loss-0.1644.
Attack - Iter-2070: Rec_loss-0.1474.
Attack - Iter-2080: Rec_loss-0.1658.
Attack - Iter-2090: Rec_loss-0.1615.
Attack - Iter-2100: Rec_loss-0.1731.
Attack - Iter-2110: Rec_loss-0.1602.
Attack - Iter-2120: Rec_loss-0.1578.
Attack - Iter-2130: Rec_loss-0.1608.
Attack - Iter-2140: Rec_loss-0.1583.
Attack - Iter-2150: Rec_loss-0.1581.
Attack - Iter-2160: Rec_loss-0.1607.
Attack - Iter-2170: Rec_loss-0.1536.
Attack - Iter-2180: Rec_loss-0.1505.
Attack - Iter-2190: Rec_loss-0.1565.
Attack - Iter-2200: Rec_loss-0.1568.
Attack - Iter-2210: Rec_loss-0.1413.
Attack - Iter-2220: Rec_loss-0.1565.
Attack - Iter-2230: Rec_loss-0.1514.
Attack - Iter-2240: Rec_loss-0.1596.
Attack - Iter-2250: Rec_loss-0.1564.
Attack - Iter-2260: Rec_loss-0.1495.
Attack - Iter-2270: Rec_loss-0.1526.
Attack - Iter-2280: Rec_loss-0.1559.
Attack - Iter-2290: Rec_loss-0.1541.
Attack - Iter-2300: Rec_loss-0.1646.
Attack - Iter-2310: Rec_loss-0.1534.
Attack - Iter-2320: Rec_loss-0.1617.
Attack - Iter-2330: Rec_loss-0.1591.
Attack - Iter-2340: Rec_loss-0.1669.
Attack - Iter-2350: Rec_loss-0.1578.
Attack - Iter-2360: Rec_loss-0.1601.
Attack - Iter-2370: Rec_loss-0.1568.
Attack - Iter-2380: Rec_loss-0.1565.
Attack - Iter-2390: Rec_loss-0.1587.
Attack - Iter-2400: Rec_loss-0.1577.
Attack - Iter-2410: Rec_loss-0.1654.
Attack - Iter-2420: Rec_loss-0.1616.
Attack - Iter-2430: Rec_loss-0.1573.
Attack - Iter-2440: Rec_loss-0.1548.
Attack - Iter-2450: Rec_loss-0.1615.
Attack - Iter-2460: Rec_loss-0.1538.
Attack - Iter-2470: Rec_loss-0.1614.
Attack - Iter-2480: Rec_loss-0.1654.
Attack - Iter-2490: Rec_loss-0.1546.
Attack - Iter-2500: Rec_loss-0.1621.
Attack - Iter-2510: Rec_loss-0.1575.
Attack - Iter-2520: Rec_loss-0.1677.
Attack - Iter-2530: Rec_loss-0.1629.
Attack - Iter-2540: Rec_loss-0.1629.
Attack - Iter-2550: Rec_loss-0.1631.
Attack - Iter-2560: Rec_loss-0.1518.
Attack - Iter-2570: Rec_loss-0.1498.
Attack - Iter-2580: Rec_loss-0.1531.
Attack - Iter-2590: Rec_loss-0.1528.
Attack - Iter-2600: Rec_loss-0.1667.
Attack - Iter-2610: Rec_loss-0.1627.
Attack - Iter-2620: Rec_loss-0.1533.
Attack - Iter-2630: Rec_loss-0.1637.
Attack - Iter-2640: Rec_loss-0.1691.
Attack - Iter-2650: Rec_loss-0.1577.
Attack - Iter-2660: Rec_loss-0.1671.
Attack - Iter-2670: Rec_loss-0.1672.
Attack - Iter-2680: Rec_loss-0.1590.
Attack - Iter-2690: Rec_loss-0.1642.
Attack - Iter-2700: Rec_loss-0.1642.
Attack - Iter-2710: Rec_loss-0.1544.
Attack - Iter-2720: Rec_loss-0.1511.
Attack - Iter-2730: Rec_loss-0.1529.
Attack - Iter-2740: Rec_loss-0.1575.
Attack - Iter-2750: Rec_loss-0.1648.
Attack - Iter-2760: Rec_loss-0.1597.
Attack - Iter-2770: Rec_loss-0.1563.
Attack - Iter-2780: Rec_loss-0.1576.
Attack - Iter-2790: Rec_loss-0.1544.
Attack - Iter-2800: Rec_loss-0.1766.
Attack - Iter-2810: Rec_loss-0.1692.
Attack - Iter-2820: Rec_loss-0.1532.
Attack - Iter-2830: Rec_loss-0.1618.
Attack - Iter-2840: Rec_loss-0.1595.
Attack - Iter-2850: Rec_loss-0.1677.
Attack - Iter-2860: Rec_loss-0.1583.
Attack - Iter-2870: Rec_loss-0.1618.
Attack - Iter-2880: Rec_loss-0.1679.
Attack - Iter-2890: Rec_loss-0.1644.
Attack - Iter-2900: Rec_loss-0.1619.
Attack - Iter-2910: Rec_loss-0.1547.
Attack - Iter-2920: Rec_loss-0.1577.
Attack - Iter-2930: Rec_loss-0.1607.
Attack - Iter-2940: Rec_loss-0.1605.
Attack - Iter-2950: Rec_loss-0.1481.
Attack - Iter-2960: Rec_loss-0.1572.
Attack - Iter-2970: Rec_loss-0.1597.
Attack - Iter-2980: Rec_loss-0.1531.
Attack - Iter-2990: Rec_loss-0.1497.
Attack - Iter-3000: Rec_loss-0.1529.
Attack - Iter-3010: Rec_loss-0.1573.
Attack - Iter-3020: Rec_loss-0.1619.
Attack - Iter-3030: Rec_loss-0.1594.
Attack - Iter-3040: Rec_loss-0.1601.
Attack - Iter-3050: Rec_loss-0.1505.
Attack - Iter-3060: Rec_loss-0.1624.
Attack - Iter-3070: Rec_loss-0.1613.
Attack - Iter-3080: Rec_loss-0.1778.
Attack - Iter-3090: Rec_loss-0.1490.
Attack - Iter-3100: Rec_loss-0.1559.
Attack - Iter-3110: Rec_loss-0.1675.
Attack - Iter-3120: Rec_loss-0.1576.
Attack - Iter-3130: Rec_loss-0.1641.
Attack - Iter-3140: Rec_loss-0.1637.
Attack - Iter-3150: Rec_loss-0.1601.
Attack - Iter-3160: Rec_loss-0.1670.
Attack - Iter-3170: Rec_loss-0.1513.
Attack - Iter-3180: Rec_loss-0.1536.
Attack - Iter-3190: Rec_loss-0.1571.
Attack - Iter-3200: Rec_loss-0.1659.
Attack - Iter-3210: Rec_loss-0.1595.
Attack - Iter-3220: Rec_loss-0.1522.
Attack - Iter-3230: Rec_loss-0.1591.
Attack - Iter-3240: Rec_loss-0.1569.
Attack - Iter-3250: Rec_loss-0.1628.
Attack - Iter-3260: Rec_loss-0.1673.
Attack - Iter-3270: Rec_loss-0.1469.
Attack - Iter-3280: Rec_loss-0.1647.
Attack - Iter-3290: Rec_loss-0.1575.
Attack - Iter-3300: Rec_loss-0.1610.
Attack - Iter-3310: Rec_loss-0.1567.
Attack - Iter-3320: Rec_loss-0.1518.
Attack - Iter-3330: Rec_loss-0.1612.
Attack - Iter-3340: Rec_loss-0.1611.
Attack - Iter-3350: Rec_loss-0.1617.
Attack - Iter-3360: Rec_loss-0.1649.
Attack - Iter-3370: Rec_loss-0.1501.
Attack - Iter-3380: Rec_loss-0.1577.
Attack - Iter-3390: Rec_loss-0.1522.
Attack - Iter-3400: Rec_loss-0.1592.
Attack - Iter-3410: Rec_loss-0.1571.
Attack - Iter-3420: Rec_loss-0.1548.
Attack - Iter-3430: Rec_loss-0.1602.
Attack - Iter-3440: Rec_loss-0.1603.
Attack - Iter-3450: Rec_loss-0.1560.
Attack - Iter-3460: Rec_loss-0.1537.
Attack - Iter-3470: Rec_loss-0.1553.
Attack - Iter-3480: Rec_loss-0.1627.
Attack - Iter-3490: Rec_loss-0.1607.
Attack - Iter-3500: Rec_loss-0.1586.
Attack - Iter-3510: Rec_loss-0.1593.
Attack - Iter-3520: Rec_loss-0.1599.
Attack - Iter-3530: Rec_loss-0.1606.
Attack - Iter-3540: Rec_loss-0.1445.
Attack - Iter-3550: Rec_loss-0.1537.
Attack - Iter-3560: Rec_loss-0.1591.
Attack - Iter-3570: Rec_loss-0.1528.
Attack - Iter-3580: Rec_loss-0.1525.
Attack - Iter-3590: Rec_loss-0.1649.
Attack - Iter-3600: Rec_loss-0.1503.
Attack - Iter-3610: Rec_loss-0.1580.
Attack - Iter-3620: Rec_loss-0.1601.
Attack - Iter-3630: Rec_loss-0.1574.
Attack - Iter-3640: Rec_loss-0.1559.
Attack - Iter-3650: Rec_loss-0.1553.
Attack - Iter-3660: Rec_loss-0.1713.
Attack - Iter-3670: Rec_loss-0.1642.
Attack - Iter-3680: Rec_loss-0.1644.
Attack - Iter-3690: Rec_loss-0.1525.
Attack - Iter-3700: Rec_loss-0.1575.
Attack - Iter-3710: Rec_loss-0.1571.
Attack - Iter-3720: Rec_loss-0.1695.
Attack - Iter-3730: Rec_loss-0.1536.
Attack - Iter-3740: Rec_loss-0.1589.
Attack - Iter-3750: Rec_loss-0.1558.
Attack - Iter-3760: Rec_loss-0.1599.
Attack - Iter-3770: Rec_loss-0.1560.
Attack - Iter-3780: Rec_loss-0.1549.
Attack - Iter-3790: Rec_loss-0.1545.
Attack - Iter-3800: Rec_loss-0.1560.
Attack - Iter-3810: Rec_loss-0.1616.
Attack - Iter-3820: Rec_loss-0.1525.
Attack - Iter-3830: Rec_loss-0.1540.
Attack - Iter-3840: Rec_loss-0.1473.
Attack - Iter-3850: Rec_loss-0.1558.
Attack - Iter-3860: Rec_loss-0.1564.
Attack - Iter-3870: Rec_loss-0.1575.
Attack - Iter-3880: Rec_loss-0.1543.
Attack - Iter-3890: Rec_loss-0.1583.
Attack - Iter-3900: Rec_loss-0.1534.
Attack - Iter-3910: Rec_loss-0.1528.
Attack - Iter-3920: Rec_loss-0.1575.
Attack - Iter-3930: Rec_loss-0.1504.
Attack - Iter-3940: Rec_loss-0.1620.
Attack - Iter-3950: Rec_loss-0.1562.
Attack - Iter-3960: Rec_loss-0.1573.
Attack - Iter-3970: Rec_loss-0.1605.
Attack - Iter-3980: Rec_loss-0.1532.
Attack - Iter-3990: Rec_loss-0.1578.
Attack - Iter-4000: Rec_loss-0.1624.
Attack - Iter-4010: Rec_loss-0.1543.
Attack - Iter-4020: Rec_loss-0.1513.
Attack - Iter-4030: Rec_loss-0.1538.
Attack - Iter-4040: Rec_loss-0.1576.
Attack - Iter-4050: Rec_loss-0.1534.
Attack - Iter-4060: Rec_loss-0.1554.
Attack - Iter-4070: Rec_loss-0.1579.
Attack - Iter-4080: Rec_loss-0.1578.
Attack - Iter-4090: Rec_loss-0.1558.
Attack - Iter-4100: Rec_loss-0.1523.
Attack - Iter-4110: Rec_loss-0.1508.
Attack - Iter-4120: Rec_loss-0.1522.
Attack - Iter-4130: Rec_loss-0.1544.
Attack - Iter-4140: Rec_loss-0.1515.
Attack - Iter-4150: Rec_loss-0.1500.
Attack - Iter-4160: Rec_loss-0.1526.
Attack - Iter-4170: Rec_loss-0.1518.
Attack - Iter-4180: Rec_loss-0.1546.
Attack - Iter-4190: Rec_loss-0.1555.
Attack - Iter-4200: Rec_loss-0.1531.
Attack - Iter-4210: Rec_loss-0.1510.
Attack - Iter-4220: Rec_loss-0.1499.
Attack - Iter-4230: Rec_loss-0.1536.
Attack - Iter-4240: Rec_loss-0.1477.
Attack - Iter-4250: Rec_loss-0.1566.
Attack - Iter-4260: Rec_loss-0.1542.
Attack - Iter-4270: Rec_loss-0.1530.
Attack - Iter-4280: Rec_loss-0.1513.
Attack - Iter-4290: Rec_loss-0.1505.
Attack - Iter-4300: Rec_loss-0.1529.
Attack - Iter-4310: Rec_loss-0.1548.
Attack - Iter-4320: Rec_loss-0.1549.
Attack - Iter-4330: Rec_loss-0.1507.
Attack - Iter-4340: Rec_loss-0.1514.
Attack - Iter-4350: Rec_loss-0.1474.
Attack - Iter-4360: Rec_loss-0.1521.
Attack - Iter-4370: Rec_loss-0.1611.
Attack - Iter-4380: Rec_loss-0.1518.
Attack - Iter-4390: Rec_loss-0.1510.
Attack - Iter-4400: Rec_loss-0.1515.
Attack - Iter-4410: Rec_loss-0.1537.
Attack - Iter-4420: Rec_loss-0.1512.
Attack - Iter-4430: Rec_loss-0.1572.
Attack - Iter-4440: Rec_loss-0.1559.
Attack - Iter-4450: Rec_loss-0.1573.
Attack - Iter-4460: Rec_loss-0.1620.
Attack - Iter-4470: Rec_loss-0.1568.
Attack - Iter-4480: Rec_loss-0.1573.
Attack - Iter-4490: Rec_loss-0.1612.
Attack - Iter-4500: Rec_loss-0.1630.
Attack - Iter-4510: Rec_loss-0.1500.
Attack - Iter-4520: Rec_loss-0.1510.
Attack - Iter-4530: Rec_loss-0.1543.
Attack - Iter-4540: Rec_loss-0.1561.
Attack - Iter-4550: Rec_loss-0.1647.
Attack - Iter-4560: Rec_loss-0.1596.
Attack - Iter-4570: Rec_loss-0.1585.
Attack - Iter-4580: Rec_loss-0.1538.
Attack - Iter-4590: Rec_loss-0.1570.
Attack - Iter-4600: Rec_loss-0.1560.
Attack - Iter-4610: Rec_loss-0.1585.
Attack - Iter-4620: Rec_loss-0.1520.
Attack - Iter-4630: Rec_loss-0.1574.
Attack - Iter-4640: Rec_loss-0.1556.
Attack - Iter-4650: Rec_loss-0.1501.
Attack - Iter-4660: Rec_loss-0.1475.
Attack - Iter-4670: Rec_loss-0.1572.
Attack - Iter-4680: Rec_loss-0.1576.
Attack - Iter-4690: Rec_loss-0.1598.
Attack - Iter-4700: Rec_loss-0.1493.
Attack - Iter-4710: Rec_loss-0.1635.
Attack - Iter-4720: Rec_loss-0.1545.
Attack - Iter-4730: Rec_loss-0.1516.
Attack - Iter-4740: Rec_loss-0.1626.
Attack - Iter-4750: Rec_loss-0.1579.
Attack - Iter-4760: Rec_loss-0.1525.
Attack - Iter-4770: Rec_loss-0.1530.
Attack - Iter-4780: Rec_loss-0.1595.
Attack - Iter-4790: Rec_loss-0.1599.
Attack - Iter-4800: Rec_loss-0.1607.
Attack - Iter-4810: Rec_loss-0.1693.
Attack - Iter-4820: Rec_loss-0.1557.
Attack - Iter-4830: Rec_loss-0.1608.
Attack - Iter-4840: Rec_loss-0.1602.
Attack - Iter-4850: Rec_loss-0.1651.
Attack - Iter-4860: Rec_loss-0.1560.
Attack - Iter-4870: Rec_loss-0.1612.
Attack - Iter-4880: Rec_loss-0.1596.
Attack - Iter-4890: Rec_loss-0.1655.
Attack - Iter-4900: Rec_loss-0.1539.
Attack - Iter-4910: Rec_loss-0.1571.
Attack - Iter-4920: Rec_loss-0.1545.
Attack - Iter-4930: Rec_loss-0.1532.
Attack - Iter-4940: Rec_loss-0.1568.
Attack - Iter-4950: Rec_loss-0.1580.
Attack - Iter-4960: Rec_loss-0.1520.
Attack - Iter-4970: Rec_loss-0.1553.
Attack - Iter-4980: Rec_loss-0.1586.
Attack - Iter-4990: Rec_loss-0.1529.
Attack - Iter-5000: Rec_loss-0.1491.
Attack - Iter-5010: Rec_loss-0.1492.
Attack - Iter-5020: Rec_loss-0.1491.
Attack - Iter-5030: Rec_loss-0.1555.
Attack - Iter-5040: Rec_loss-0.1542.
Attack - Iter-5050: Rec_loss-0.1533.
Attack - Iter-5060: Rec_loss-0.1515.
Attack - Iter-5070: Rec_loss-0.1525.
Attack - Iter-5080: Rec_loss-0.1555.
Attack - Iter-5090: Rec_loss-0.1515.
Attack - Iter-5100: Rec_loss-0.1509.
Attack - Iter-5110: Rec_loss-0.1509.
Attack - Iter-5120: Rec_loss-0.1564.
Attack - Iter-5130: Rec_loss-0.1564.
Attack - Iter-5140: Rec_loss-0.1518.
Attack - Iter-5150: Rec_loss-0.1619.
Attack - Iter-5160: Rec_loss-0.1571.
Attack - Iter-5170: Rec_loss-0.1598.
Attack - Iter-5180: Rec_loss-0.1571.
Attack - Iter-5190: Rec_loss-0.1581.
Attack - Iter-5200: Rec_loss-0.1510.
Attack - Iter-5210: Rec_loss-0.1584.
Attack - Iter-5220: Rec_loss-0.1624.
Attack - Iter-5230: Rec_loss-0.1545.
Attack - Iter-5240: Rec_loss-0.1625.
Attack - Iter-5250: Rec_loss-0.1503.
Attack - Iter-5260: Rec_loss-0.1490.
Attack - Iter-5270: Rec_loss-0.1576.
Attack - Iter-5280: Rec_loss-0.1553.
Attack - Iter-5290: Rec_loss-0.1523.
Attack - Iter-5300: Rec_loss-0.1539.
Attack - Iter-5310: Rec_loss-0.1566.
Attack - Iter-5320: Rec_loss-0.1642.
Attack - Iter-5330: Rec_loss-0.1569.
Attack - Iter-5340: Rec_loss-0.1570.
Attack - Iter-5350: Rec_loss-0.1651.
Attack - Iter-5360: Rec_loss-0.1571.
Attack - Iter-5370: Rec_loss-0.1652.
Attack - Iter-5380: Rec_loss-0.1548.
Attack - Iter-5390: Rec_loss-0.1555.
Attack - Iter-5400: Rec_loss-0.1534.
Attack - Iter-5410: Rec_loss-0.1504.
Attack - Iter-5420: Rec_loss-0.1518.
Attack - Iter-5430: Rec_loss-0.1559.
Attack - Iter-5440: Rec_loss-0.1497.
Attack - Iter-5450: Rec_loss-0.1522.
Attack - Iter-5460: Rec_loss-0.1542.
Attack - Iter-5470: Rec_loss-0.1527.
Attack - Iter-5480: Rec_loss-0.1546.
Attack - Iter-5490: Rec_loss-0.1495.
Attack - Iter-5500: Rec_loss-0.1556.
Attack - Iter-5510: Rec_loss-0.1464.
Attack - Iter-5520: Rec_loss-0.1546.
Attack - Iter-5530: Rec_loss-0.1553.
Attack - Iter-5540: Rec_loss-0.1500.
Attack - Iter-5550: Rec_loss-0.1560.
Attack - Iter-5560: Rec_loss-0.1520.
Attack - Iter-5570: Rec_loss-0.1584.
Attack - Iter-5580: Rec_loss-0.1520.
Attack - Iter-5590: Rec_loss-0.1508.
Attack - Iter-5600: Rec_loss-0.1584.
Attack - Iter-5610: Rec_loss-0.1569.
Attack - Iter-5620: Rec_loss-0.1563.
Attack - Iter-5630: Rec_loss-0.1552.
Attack - Iter-5640: Rec_loss-0.1489.
Attack - Iter-5650: Rec_loss-0.1505.
Attack - Iter-5660: Rec_loss-0.1511.
Attack - Iter-5670: Rec_loss-0.1530.
Attack - Iter-5680: Rec_loss-0.1511.
Attack - Iter-5690: Rec_loss-0.1552.
Attack - Iter-5700: Rec_loss-0.1522.
Attack - Iter-5710: Rec_loss-0.1571.
Attack - Iter-5720: Rec_loss-0.1413.
Attack - Iter-5730: Rec_loss-0.1460.
Attack - Iter-5740: Rec_loss-0.1478.
Attack - Iter-5750: Rec_loss-0.1497.
Attack - Iter-5760: Rec_loss-0.1501.
Attack - Iter-5770: Rec_loss-0.1567.
Attack - Iter-5780: Rec_loss-0.1455.
Attack - Iter-5790: Rec_loss-0.1492.
Attack - Iter-5800: Rec_loss-0.1537.
Attack - Iter-5810: Rec_loss-0.1474.
Attack - Iter-5820: Rec_loss-0.1436.
Attack - Iter-5830: Rec_loss-0.1438.
Attack - Iter-5840: Rec_loss-0.1518.
Attack - Iter-5850: Rec_loss-0.1522.
Attack - Iter-5860: Rec_loss-0.1569.
Attack - Iter-5870: Rec_loss-0.1464.
Attack - Iter-5880: Rec_loss-0.1528.
Attack - Iter-5890: Rec_loss-0.1560.
Attack - Iter-5900: Rec_loss-0.1446.
Attack - Iter-5910: Rec_loss-0.1568.
Attack - Iter-5920: Rec_loss-0.1531.
Attack - Iter-5930: Rec_loss-0.1474.
Attack - Iter-5940: Rec_loss-0.1527.
Attack - Iter-5950: Rec_loss-0.1480.
Attack - Iter-5960: Rec_loss-0.1477.
Attack - Iter-5970: Rec_loss-0.1473.
Attack - Iter-5980: Rec_loss-0.1549.
Attack - Iter-5990: Rec_loss-0.1521.
Attack - Iter-6000: Rec_loss-0.1446.
Attack - Iter-6010: Rec_loss-0.1434.
Attack - Iter-6020: Rec_loss-0.1503.
Attack - Iter-6030: Rec_loss-0.1520.
Attack - Iter-6040: Rec_loss-0.1524.
Attack - Iter-6050: Rec_loss-0.1494.
Attack - Iter-6060: Rec_loss-0.1506.
Attack - Iter-6070: Rec_loss-0.1484.
Attack - Iter-6080: Rec_loss-0.1471.
Attack - Iter-6090: Rec_loss-0.1518.
Attack - Iter-6100: Rec_loss-0.1575.
Attack - Iter-6110: Rec_loss-0.1566.
Attack - Iter-6120: Rec_loss-0.1510.
Attack - Iter-6130: Rec_loss-0.1482.
Attack - Iter-6140: Rec_loss-0.1458.
Attack - Iter-6150: Rec_loss-0.1461.
Attack - Iter-6160: Rec_loss-0.1481.
Attack - Iter-6170: Rec_loss-0.1453.
Attack - Iter-6180: Rec_loss-0.1530.
Attack - Iter-6190: Rec_loss-0.1510.
Attack - Iter-6200: Rec_loss-0.1505.
Attack - Iter-6210: Rec_loss-0.1509.
Attack - Iter-6220: Rec_loss-0.1442.
Attack - Iter-6230: Rec_loss-0.1503.
Attack - Iter-6240: Rec_loss-0.1455.
Attack - Iter-6250: Rec_loss-0.1494.
Attack - Iter-6260: Rec_loss-0.1455.
Attack - Iter-6270: Rec_loss-0.1384.
Attack - Iter-6280: Rec_loss-0.1508.
Attack - Iter-6290: Rec_loss-0.1466.
Attack - Iter-6300: Rec_loss-0.1484.
Attack - Iter-6310: Rec_loss-0.1535.
Attack - Iter-6320: Rec_loss-0.1505.
Attack - Iter-6330: Rec_loss-0.1495.
Attack - Iter-6340: Rec_loss-0.1483.
Attack - Iter-6350: Rec_loss-0.1458.
Attack - Iter-6360: Rec_loss-0.1472.
Attack - Iter-6370: Rec_loss-0.1463.
Attack - Iter-6380: Rec_loss-0.1514.
Attack - Iter-6390: Rec_loss-0.1481.
Attack - Iter-6400: Rec_loss-0.1515.
Attack - Iter-6410: Rec_loss-0.1516.
Attack - Iter-6420: Rec_loss-0.1494.
Attack - Iter-6430: Rec_loss-0.1543.
Attack - Iter-6440: Rec_loss-0.1536.
Attack - Iter-6450: Rec_loss-0.1486.
Attack - Iter-6460: Rec_loss-0.1432.
Attack - Iter-6470: Rec_loss-0.1494.
Attack - Iter-6480: Rec_loss-0.1469.
Attack - Iter-6490: Rec_loss-0.1520.
Attack - Iter-6500: Rec_loss-0.1528.
Attack - Iter-6510: Rec_loss-0.1505.
Attack - Iter-6520: Rec_loss-0.1431.
Attack - Iter-6530: Rec_loss-0.1455.
Attack - Iter-6540: Rec_loss-0.1525.
Attack - Iter-6550: Rec_loss-0.1538.
Attack - Iter-6560: Rec_loss-0.1484.
Attack - Iter-6570: Rec_loss-0.1498.
Attack - Iter-6580: Rec_loss-0.1527.
Attack - Iter-6590: Rec_loss-0.1486.
Attack - Iter-6600: Rec_loss-0.1470.
Attack - Iter-6610: Rec_loss-0.1415.
Attack - Iter-6620: Rec_loss-0.1531.
Attack - Iter-6630: Rec_loss-0.1494.
Attack - Iter-6640: Rec_loss-0.1453.
Attack - Iter-6650: Rec_loss-0.1469.
Attack - Iter-6660: Rec_loss-0.1479.
Attack - Iter-6670: Rec_loss-0.1475.
Attack - Iter-6680: Rec_loss-0.1521.
Attack - Iter-6690: Rec_loss-0.1514.
Attack - Iter-6700: Rec_loss-0.1427.
Attack - Iter-6710: Rec_loss-0.1495.
Attack - Iter-6720: Rec_loss-0.1486.
Attack - Iter-6730: Rec_loss-0.1436.
Attack - Iter-6740: Rec_loss-0.1391.
Attack - Iter-6750: Rec_loss-0.1475.
Attack - Iter-6760: Rec_loss-0.1460.
Attack - Iter-6770: Rec_loss-0.1509.
Attack - Iter-6780: Rec_loss-0.1507.
Attack - Iter-6790: Rec_loss-0.1459.
Attack - Iter-6800: Rec_loss-0.1491.
Attack - Iter-6810: Rec_loss-0.1491.
Attack - Iter-6820: Rec_loss-0.1546.
Attack - Iter-6830: Rec_loss-0.1562.
Attack - Iter-6840: Rec_loss-0.1548.
Attack - Iter-6850: Rec_loss-0.1488.
Attack - Iter-6860: Rec_loss-0.1484.
Attack - Iter-6870: Rec_loss-0.1507.
Attack - Iter-6880: Rec_loss-0.1476.
Attack - Iter-6890: Rec_loss-0.1468.
Attack - Iter-6900: Rec_loss-0.1562.
Attack - Iter-6910: Rec_loss-0.1495.
Attack - Iter-6920: Rec_loss-0.1453.
Attack - Iter-6930: Rec_loss-0.1471.
Attack - Iter-6940: Rec_loss-0.1495.
Attack - Iter-6950: Rec_loss-0.1460.
Attack - Iter-6960: Rec_loss-0.1507.
Attack - Iter-6970: Rec_loss-0.1486.
Attack - Iter-6980: Rec_loss-0.1464.
Attack - Iter-6990: Rec_loss-0.1455.
Attack - Iter-7000: Rec_loss-0.1510.
Attack - Iter-7010: Rec_loss-0.1498.
Attack - Iter-7020: Rec_loss-0.1459.
Attack - Iter-7030: Rec_loss-0.1476.
Attack - Iter-7040: Rec_loss-0.1468.
Attack - Iter-7050: Rec_loss-0.1494.
Attack - Iter-7060: Rec_loss-0.1498.
Attack - Iter-7070: Rec_loss-0.1454.
Attack - Iter-7080: Rec_loss-0.1481.
Attack - Iter-7090: Rec_loss-0.1461.
Attack - Iter-7100: Rec_loss-0.1511.
Attack - Iter-7110: Rec_loss-0.1514.
Attack - Iter-7120: Rec_loss-0.1474.
Attack - Iter-7130: Rec_loss-0.1489.
Attack - Iter-7140: Rec_loss-0.1446.
Attack - Iter-7150: Rec_loss-0.1481.
Attack - Iter-7160: Rec_loss-0.1474.
Attack - Iter-7170: Rec_loss-0.1529.
Attack - Iter-7180: Rec_loss-0.1425.
Attack - Iter-7190: Rec_loss-0.1468.
Attack - Iter-7200: Rec_loss-0.1458.
Attack - Iter-7210: Rec_loss-0.1447.
Attack - Iter-7220: Rec_loss-0.1490.
Attack - Iter-7230: Rec_loss-0.1483.
Attack - Iter-7240: Rec_loss-0.1504.
Attack - Iter-7250: Rec_loss-0.1428.
Attack - Iter-7260: Rec_loss-0.1537.
Attack - Iter-7270: Rec_loss-0.1540.
Attack - Iter-7280: Rec_loss-0.1494.
Attack - Iter-7290: Rec_loss-0.1517.
Attack - Iter-7300: Rec_loss-0.1462.
Attack - Iter-7310: Rec_loss-0.1458.
Attack - Iter-7320: Rec_loss-0.1451.
Attack - Iter-7330: Rec_loss-0.1503.
Attack - Iter-7340: Rec_loss-0.1475.
Attack - Iter-7350: Rec_loss-0.1540.
Attack - Iter-7360: Rec_loss-0.1488.
Attack - Iter-7370: Rec_loss-0.1466.
Attack - Iter-7380: Rec_loss-0.1492.
Attack - Iter-7390: Rec_loss-0.1451.
Attack - Iter-7400: Rec_loss-0.1475.
Attack - Iter-7410: Rec_loss-0.1535.
Attack - Iter-7420: Rec_loss-0.1498.
Attack - Iter-7430: Rec_loss-0.1424.
Attack - Iter-7440: Rec_loss-0.1456.
Attack - Iter-7450: Rec_loss-0.1466.
Attack - Iter-7460: Rec_loss-0.1432.
Attack - Iter-7470: Rec_loss-0.1477.
Attack - Iter-7480: Rec_loss-0.1481.
Attack - Iter-7490: Rec_loss-0.1475.
Attack - Iter-7500: Rec_loss-0.1482.
Attack - Iter-7510: Rec_loss-0.1497.
Attack - Iter-7520: Rec_loss-0.1516.
Attack - Iter-7530: Rec_loss-0.1449.
Attack - Iter-7540: Rec_loss-0.1443.
Attack - Iter-7550: Rec_loss-0.1469.
Attack - Iter-7560: Rec_loss-0.1463.
Attack - Iter-7570: Rec_loss-0.1520.
Attack - Iter-7580: Rec_loss-0.1500.
Attack - Iter-7590: Rec_loss-0.1476.
Attack - Iter-7600: Rec_loss-0.1507.
Attack - Iter-7610: Rec_loss-0.1446.
Attack - Iter-7620: Rec_loss-0.1451.
Attack - Iter-7630: Rec_loss-0.1471.
Attack - Iter-7640: Rec_loss-0.1502.
Attack - Iter-7650: Rec_loss-0.1500.
Attack - Iter-7660: Rec_loss-0.1448.
Attack - Iter-7670: Rec_loss-0.1454.
Attack - Iter-7680: Rec_loss-0.1506.
Attack - Iter-7690: Rec_loss-0.1527.
Attack - Iter-7700: Rec_loss-0.1527.
Attack - Iter-7710: Rec_loss-0.1494.
Attack - Iter-7720: Rec_loss-0.1507.
Attack - Iter-7730: Rec_loss-0.1473.
Attack - Iter-7740: Rec_loss-0.1476.
Attack - Iter-7750: Rec_loss-0.1574.
Attack - Iter-7760: Rec_loss-0.1450.
Attack - Iter-7770: Rec_loss-0.1463.
Attack - Iter-7780: Rec_loss-0.1478.
Attack - Iter-7790: Rec_loss-0.1488.
Attack - Iter-7800: Rec_loss-0.1501.
Attack - Iter-7810: Rec_loss-0.1514.
Attack - Iter-7820: Rec_loss-0.1456.
Attack - Iter-7830: Rec_loss-0.1507.
Attack - Iter-7840: Rec_loss-0.1510.
Attack - Iter-7850: Rec_loss-0.1494.
Attack - Iter-7860: Rec_loss-0.1553.
Attack - Iter-7870: Rec_loss-0.1466.
Attack - Iter-7880: Rec_loss-0.1500.
Attack - Iter-7890: Rec_loss-0.1474.
Attack - Iter-7900: Rec_loss-0.1504.
Attack - Iter-7910: Rec_loss-0.1521.
Attack - Iter-7920: Rec_loss-0.1494.
Attack - Iter-7930: Rec_loss-0.1520.
Attack - Iter-7940: Rec_loss-0.1507.
Attack - Iter-7950: Rec_loss-0.1499.
Attack - Iter-7960: Rec_loss-0.1508.
Attack - Iter-7970: Rec_loss-0.1489.
Attack - Iter-7980: Rec_loss-0.1482.
Attack - Iter-7990: Rec_loss-0.1473.
Attack - Iter-8000: Rec_loss-0.1528.
Attack - Iter-8010: Rec_loss-0.1549.
Attack - Iter-8020: Rec_loss-0.1526.
Attack - Iter-8030: Rec_loss-0.1508.
Attack - Iter-8040: Rec_loss-0.1495.
Attack - Iter-8050: Rec_loss-0.1475.
Attack - Iter-8060: Rec_loss-0.1498.
Attack - Iter-8070: Rec_loss-0.1541.
Attack - Iter-8080: Rec_loss-0.1512.
Attack - Iter-8090: Rec_loss-0.1489.
Attack - Iter-8100: Rec_loss-0.1532.
Attack - Iter-8110: Rec_loss-0.1481.
Attack - Iter-8120: Rec_loss-0.1535.
Attack - Iter-8130: Rec_loss-0.1482.
Attack - Iter-8140: Rec_loss-0.1493.
Attack - Iter-8150: Rec_loss-0.1487.
Attack - Iter-8160: Rec_loss-0.1507.
Attack - Iter-8170: Rec_loss-0.1495.
Attack - Iter-8180: Rec_loss-0.1571.
Attack - Iter-8190: Rec_loss-0.1516.
Attack - Iter-8200: Rec_loss-0.1506.
Attack - Iter-8210: Rec_loss-0.1515.
Attack - Iter-8220: Rec_loss-0.1526.
Attack - Iter-8230: Rec_loss-0.1559.
Attack - Iter-8240: Rec_loss-0.1500.
Attack - Iter-8250: Rec_loss-0.1484.
Attack - Iter-8260: Rec_loss-0.1499.
Attack - Iter-8270: Rec_loss-0.1532.
Attack - Iter-8280: Rec_loss-0.1511.
Attack - Iter-8290: Rec_loss-0.1495.
Attack - Iter-8300: Rec_loss-0.1511.
Attack - Iter-8310: Rec_loss-0.1504.
Attack - Iter-8320: Rec_loss-0.1496.
Attack - Iter-8330: Rec_loss-0.1554.
Attack - Iter-8340: Rec_loss-0.1479.
Attack - Iter-8350: Rec_loss-0.1519.
Attack - Iter-8360: Rec_loss-0.1488.
Attack - Iter-8370: Rec_loss-0.1532.
Attack - Iter-8380: Rec_loss-0.1522.
Attack - Iter-8390: Rec_loss-0.1563.
Attack - Iter-8400: Rec_loss-0.1482.
Attack - Iter-8410: Rec_loss-0.1521.
Attack - Iter-8420: Rec_loss-0.1527.
Attack - Iter-8430: Rec_loss-0.1515.
Attack - Iter-8440: Rec_loss-0.1519.
Attack - Iter-8450: Rec_loss-0.1505.
Attack - Iter-8460: Rec_loss-0.1522.
Attack - Iter-8470: Rec_loss-0.1494.
Attack - Iter-8480: Rec_loss-0.1428.
Attack - Iter-8490: Rec_loss-0.1464.
Attack - Iter-8500: Rec_loss-0.1448.
Attack - Iter-8510: Rec_loss-0.1479.
Attack - Iter-8520: Rec_loss-0.1410.
Attack - Iter-8530: Rec_loss-0.1494.
Attack - Iter-8540: Rec_loss-0.1507.
Attack - Iter-8550: Rec_loss-0.1502.
Attack - Iter-8560: Rec_loss-0.1510.
Attack - Iter-8570: Rec_loss-0.1483.
Attack - Iter-8580: Rec_loss-0.1473.
Attack - Iter-8590: Rec_loss-0.1456.
Attack - Iter-8600: Rec_loss-0.1458.
Attack - Iter-8610: Rec_loss-0.1509.
Attack - Iter-8620: Rec_loss-0.1481.
Attack - Iter-8630: Rec_loss-0.1533.
Attack - Iter-8640: Rec_loss-0.1492.
Attack - Iter-8650: Rec_loss-0.1511.
Attack - Iter-8660: Rec_loss-0.1503.
Attack - Iter-8670: Rec_loss-0.1526.
Attack - Iter-8680: Rec_loss-0.1525.
Attack - Iter-8690: Rec_loss-0.1464.
Attack - Iter-8700: Rec_loss-0.1443.
Attack - Iter-8710: Rec_loss-0.1513.
Attack - Iter-8720: Rec_loss-0.1486.
Attack - Iter-8730: Rec_loss-0.1484.
Attack - Iter-8740: Rec_loss-0.1463.
Attack - Iter-8750: Rec_loss-0.1464.
Attack - Iter-8760: Rec_loss-0.1508.
Attack - Iter-8770: Rec_loss-0.1486.
Attack - Iter-8780: Rec_loss-0.1480.
Attack - Iter-8790: Rec_loss-0.1483.
Attack - Iter-8800: Rec_loss-0.1481.
Attack - Iter-8810: Rec_loss-0.1491.
Attack - Iter-8820: Rec_loss-0.1540.
Attack - Iter-8830: Rec_loss-0.1463.
Attack - Iter-8840: Rec_loss-0.1507.
Attack - Iter-8850: Rec_loss-0.1464.
Attack - Iter-8860: Rec_loss-0.1527.
Attack - Iter-8870: Rec_loss-0.1476.
Attack - Iter-8880: Rec_loss-0.1458.
Attack - Iter-8890: Rec_loss-0.1492.
Attack - Iter-8900: Rec_loss-0.1518.
Attack - Iter-8910: Rec_loss-0.1509.
Attack - Iter-8920: Rec_loss-0.1515.
Attack - Iter-8930: Rec_loss-0.1483.
Attack - Iter-8940: Rec_loss-0.1495.
Attack - Iter-8950: Rec_loss-0.1484.
Attack - Iter-8960: Rec_loss-0.1481.
Attack - Iter-8970: Rec_loss-0.1528.
Attack - Iter-8980: Rec_loss-0.1442.
Attack - Iter-8990: Rec_loss-0.1479.
Attack - Iter-9000: Rec_loss-0.1479.
Attack - Iter-9010: Rec_loss-0.1472.
Attack - Iter-9020: Rec_loss-0.1493.
Attack - Iter-9030: Rec_loss-0.1487.
Attack - Iter-9040: Rec_loss-0.1481.
Attack - Iter-9050: Rec_loss-0.1485.
Attack - Iter-9060: Rec_loss-0.1496.
Attack - Iter-9070: Rec_loss-0.1478.
Attack - Iter-9080: Rec_loss-0.1437.
Attack - Iter-9090: Rec_loss-0.1453.
Attack - Iter-9100: Rec_loss-0.1460.
Attack - Iter-9110: Rec_loss-0.1515.
Attack - Iter-9120: Rec_loss-0.1515.
Attack - Iter-9130: Rec_loss-0.1508.
Attack - Iter-9140: Rec_loss-0.1438.
Attack - Iter-9150: Rec_loss-0.1457.
Attack - Iter-9160: Rec_loss-0.1528.
Attack - Iter-9170: Rec_loss-0.1500.
Attack - Iter-9180: Rec_loss-0.1465.
Attack - Iter-9190: Rec_loss-0.1489.
Attack - Iter-9200: Rec_loss-0.1455.
Attack - Iter-9210: Rec_loss-0.1484.
Attack - Iter-9220: Rec_loss-0.1543.
Attack - Iter-9230: Rec_loss-0.1488.
Attack - Iter-9240: Rec_loss-0.1502.
Attack - Iter-9250: Rec_loss-0.1424.
Attack - Iter-9260: Rec_loss-0.1506.
Attack - Iter-9270: Rec_loss-0.1531.
Attack - Iter-9280: Rec_loss-0.1487.
Attack - Iter-9290: Rec_loss-0.1502.
Attack - Iter-9300: Rec_loss-0.1521.
Attack - Iter-9310: Rec_loss-0.1484.
Attack - Iter-9320: Rec_loss-0.1466.
Attack - Iter-9330: Rec_loss-0.1507.
Attack - Iter-9340: Rec_loss-0.1509.
Attack - Iter-9350: Rec_loss-0.1511.
Attack - Iter-9360: Rec_loss-0.1467.
Attack - Iter-9370: Rec_loss-0.1492.
Attack - Iter-9380: Rec_loss-0.1539.
Attack - Iter-9390: Rec_loss-0.1395.
Attack - Iter-9400: Rec_loss-0.1498.
Attack - Iter-9410: Rec_loss-0.1499.
Attack - Iter-9420: Rec_loss-0.1504.
Attack - Iter-9430: Rec_loss-0.1501.
Attack - Iter-9440: Rec_loss-0.1490.
Attack - Iter-9450: Rec_loss-0.1477.
Attack - Iter-9460: Rec_loss-0.1522.
Attack - Iter-9470: Rec_loss-0.1488.
Attack - Iter-9480: Rec_loss-0.1486.
Attack - Iter-9490: Rec_loss-0.1486.
Attack - Iter-9500: Rec_loss-0.1475.
Attack - Iter-9510: Rec_loss-0.1504.
Attack - Iter-9520: Rec_loss-0.1515.
Attack - Iter-9530: Rec_loss-0.1485.
Attack - Iter-9540: Rec_loss-0.1488.
Attack - Iter-9550: Rec_loss-0.1505.
Attack - Iter-9560: Rec_loss-0.1516.
Attack - Iter-9570: Rec_loss-0.1486.
Attack - Iter-9580: Rec_loss-0.1521.
Attack - Iter-9590: Rec_loss-0.1504.
Attack - Iter-9600: Rec_loss-0.1490.
Attack - Iter-9610: Rec_loss-0.1504.
Attack - Iter-9620: Rec_loss-0.1508.
Attack - Iter-9630: Rec_loss-0.1440.
Attack - Iter-9640: Rec_loss-0.1481.
Attack - Iter-9650: Rec_loss-0.1489.
Attack - Iter-9660: Rec_loss-0.1474.
Attack - Iter-9670: Rec_loss-0.1524.
Attack - Iter-9680: Rec_loss-0.1448.
Attack - Iter-9690: Rec_loss-0.1424.
Attack - Iter-9700: Rec_loss-0.1553.
Attack - Iter-9710: Rec_loss-0.1501.
Attack - Iter-9720: Rec_loss-0.1493.
Attack - Iter-9730: Rec_loss-0.1494.
Attack - Iter-9740: Rec_loss-0.1538.
Attack - Iter-9750: Rec_loss-0.1504.
Attack - Iter-9760: Rec_loss-0.1509.
Attack - Iter-9770: Rec_loss-0.1519.
Attack - Iter-9780: Rec_loss-0.1493.
Attack - Iter-9790: Rec_loss-0.1519.
Attack - Iter-9800: Rec_loss-0.1519.
Attack - Iter-9810: Rec_loss-0.1504.
Attack - Iter-9820: Rec_loss-0.1524.
Attack - Iter-9830: Rec_loss-0.1469.
Attack - Iter-9840: Rec_loss-0.1516.
Attack - Iter-9850: Rec_loss-0.1492.
Attack - Iter-9860: Rec_loss-0.1491.
Attack - Iter-9870: Rec_loss-0.1473.
Attack - Iter-9880: Rec_loss-0.1471.
Attack - Iter-9890: Rec_loss-0.1503.
Attack - Iter-9900: Rec_loss-0.1512.
Attack - Iter-9910: Rec_loss-0.1523.
Attack - Iter-9920: Rec_loss-0.1479.
Attack - Iter-9930: Rec_loss-0.1502.
Attack - Iter-9940: Rec_loss-0.1509.
Attack - Iter-9950: Rec_loss-0.1497.
Attack - Iter-9960: Rec_loss-0.1496.
Attack - Iter-9970: Rec_loss-0.1495.
Attack - Iter-9980: Rec_loss-0.1461.
Attack - Iter-9990: Rec_loss-0.1502.
Attack - Iter-9999: Rec_loss-0.1550.
PSNR 19.9914 SSIM 0.6144 LPIPS -0.0000
Tuesday, 29. October 2024 09:34PM
Finished computations with time: 0:02:33.791425
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=50.0, layer_num=60, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([2])
Initial with CIFAR10
torch.Size([256, 256, 3, 3]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([64, 64, 3, 3])
16
torch.Size([64])
17
torch.Size([64])
18
torch.Size([64, 64, 3, 3])
19
torch.Size([64])
20
torch.Size([64])
21
torch.Size([128, 64, 3, 3])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 64, 1, 1])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([128, 128, 3, 3])
31
torch.Size([128])
32
torch.Size([128])
33
torch.Size([128, 128, 3, 3])
34
torch.Size([128])
35
torch.Size([128])
36
torch.Size([128, 128, 3, 3])
37
torch.Size([128])
38
torch.Size([128])
39
torch.Size([128, 128, 3, 3])
40
torch.Size([128])
41
torch.Size([128])
42
torch.Size([128, 128, 3, 3])
43
torch.Size([128])
44
torch.Size([128])
45
torch.Size([128, 128, 3, 3])
46
torch.Size([128])
47
torch.Size([128])
48
torch.Size([256, 128, 3, 3])
49
torch.Size([256])
50
torch.Size([256])
51
torch.Size([256, 256, 3, 3])
52
torch.Size([256])
53
torch.Size([256])
54
torch.Size([256, 128, 1, 1])
55
torch.Size([256])
56
torch.Size([256])
57
torch.Size([256, 256, 3, 3])
58
torch.Size([256])
59
torch.Size([256])
60
torch.Size([256, 256, 3, 3])
61
torch.Size([256])
62
torch.Size([256])
63
torch.Size([256, 256, 3, 3])
64
torch.Size([256])
65
torch.Size([256])
66
torch.Size([256, 256, 3, 3])
67
torch.Size([256])
68
torch.Size([256])
69
torch.Size([256, 256, 3, 3])
70
torch.Size([256])
71
torch.Size([256])
72
torch.Size([256, 256, 3, 3])
73
torch.Size([256])
74
torch.Size([256])
75
torch.Size([256, 256, 3, 3])
76
torch.Size([256])
77
torch.Size([256])
78
torch.Size([256, 256, 3, 3])
79
torch.Size([256])
80
torch.Size([256])
81
torch.Size([256, 256, 3, 3])
82
torch.Size([256])
83
torch.Size([256])
84
torch.Size([256, 256, 3, 3])
85
torch.Size([256])
86
torch.Size([256])
87
torch.Size([512, 256, 3, 3])
88
torch.Size([512])
89
torch.Size([512])
90
torch.Size([512, 512, 3, 3])
91
torch.Size([512])
92
torch.Size([512])
93
torch.Size([512, 256, 1, 1])
94
torch.Size([512])
95
torch.Size([512])
96
torch.Size([512, 512, 3, 3])
97
torch.Size([512])
98
torch.Size([512])
99
torch.Size([512, 512, 3, 3])
100
torch.Size([512])
101
torch.Size([512])
102
torch.Size([512, 512, 3, 3])
103
torch.Size([512])
104
torch.Size([512])
105
torch.Size([512, 512, 3, 3])
106
torch.Size([512])
107
torch.Size([512])
108
torch.Size([10, 512])
109
torch.Size([10])
110
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=50.0, layer_num=108, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([2])
Initial with CIFAR10
torch.Size([10, 512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([64, 64, 3, 3])
16
torch.Size([64])
17
torch.Size([64])
18
torch.Size([64, 64, 3, 3])
19
torch.Size([64])
20
torch.Size([64])
21
torch.Size([128, 64, 3, 3])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 64, 1, 1])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([128, 128, 3, 3])
31
torch.Size([128])
32
torch.Size([128])
33
torch.Size([128, 128, 3, 3])
34
torch.Size([128])
35
torch.Size([128])
36
torch.Size([128, 128, 3, 3])
37
torch.Size([128])
38
torch.Size([128])
39
torch.Size([128, 128, 3, 3])
40
torch.Size([128])
41
torch.Size([128])
42
torch.Size([128, 128, 3, 3])
43
torch.Size([128])
44
torch.Size([128])
45
torch.Size([128, 128, 3, 3])
46
torch.Size([128])
47
torch.Size([128])
48
torch.Size([256, 128, 3, 3])
49
torch.Size([256])
50
torch.Size([256])
51
torch.Size([256, 256, 3, 3])
52
torch.Size([256])
53
torch.Size([256])
54
torch.Size([256, 128, 1, 1])
55
torch.Size([256])
56
torch.Size([256])
57
torch.Size([256, 256, 3, 3])
58
torch.Size([256])
59
torch.Size([256])
60
torch.Size([256, 256, 3, 3])
61
torch.Size([256])
62
torch.Size([256])
63
torch.Size([256, 256, 3, 3])
64
torch.Size([256])
65
torch.Size([256])
66
torch.Size([256, 256, 3, 3])
67
torch.Size([256])
68
torch.Size([256])
69
torch.Size([256, 256, 3, 3])
70
torch.Size([256])
71
torch.Size([256])
72
torch.Size([256, 256, 3, 3])
73
torch.Size([256])
74
torch.Size([256])
75
torch.Size([256, 256, 3, 3])
76
torch.Size([256])
77
torch.Size([256])
78
torch.Size([256, 256, 3, 3])
79
torch.Size([256])
80
torch.Size([256])
81
torch.Size([256, 256, 3, 3])
82
torch.Size([256])
83
torch.Size([256])
84
torch.Size([256, 256, 3, 3])
85
torch.Size([256])
86
torch.Size([256])
87
torch.Size([512, 256, 3, 3])
88
torch.Size([512])
89
torch.Size([512])
90
torch.Size([512, 512, 3, 3])
91
torch.Size([512])
92
torch.Size([512])
93
torch.Size([512, 256, 1, 1])
94
torch.Size([512])
95
torch.Size([512])
96
torch.Size([512, 512, 3, 3])
97
torch.Size([512])
98
torch.Size([512])
99
torch.Size([512, 512, 3, 3])
100
torch.Size([512])
101
torch.Size([512])
102
torch.Size([512, 512, 3, 3])
103
torch.Size([512])
104
torch.Size([512])
105
torch.Size([512, 512, 3, 3])
106
torch.Size([512])
107
torch.Size([512])
108
torch.Size([10, 512])
109
torch.Size([10])
110
Finished defence with time: 0:00:26.513249
Attack - Iter-0: Rec_loss-0.3775.
Attack - Iter-1000: Rec_loss-0.3183.
Attack - Iter-2000: Rec_loss-0.3255.
Attack - Iter-3000: Rec_loss-0.3242.
Attack - Iter-4000: Rec_loss-0.3286.
Attack - Iter-5000: Rec_loss-0.3267.
Attack - Iter-6000: Rec_loss-0.3126.
Attack - Iter-7000: Rec_loss-0.3163.
Attack - Iter-8000: Rec_loss-0.3160.
Attack - Iter-9000: Rec_loss-0.3193.
Attack - Iter-9999: Rec_loss-0.3173.
PSNR 10.6057 SSIM 0.2855 LPIPS -0.0000
Tuesday, 29. October 2024 10:18PM
Finished computations with time: 0:03:36.536908
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=50.0, layer_num=60, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([10, 512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:25.001513
Attack - Iter-0: Rec_loss-0.4180.
Attack - Iter-1000: Rec_loss-0.1624.
Attack - Iter-2000: Rec_loss-0.1635.
Attack - Iter-3000: Rec_loss-0.1529.
Attack - Iter-4000: Rec_loss-0.1624.
Attack - Iter-5000: Rec_loss-0.1491.
Attack - Iter-6000: Rec_loss-0.1446.
Attack - Iter-7000: Rec_loss-0.1510.
Attack - Iter-8000: Rec_loss-0.1528.
Attack - Iter-9000: Rec_loss-0.1479.
Attack - Iter-9999: Rec_loss-0.1550.
PSNR 19.9914 SSIM 0.6144 LPIPS -0.0000
Tuesday, 29. October 2024 10:25PM
Finished computations with time: 0:02:32.849627
Namespace(seed=42, output_dir='./logs', root='/home/lgd/Desktop/SNNFL/datasets', dataset='CIFAR10', num_workers=2, batch_size=1, num_sen=1, batch_idx=3, pretrained=False, demo=True, attack='gs', max_iter=10000, lr=0.1, lr_decay=True, tv=0.0001, boxed=False, imprint='no_sparse', bins=10, prior=-1, defense='soteria', percent_num=50.0, layer_num=60, perturb_imprint=False, noise_name='Gaussian', loc=0.0, scale=0.0001, per_adv=1, dcs_iter=300, dcs_lr=0.1, lambda_xsim=0.01, lambda_zsim=0.01, epsilon=0.01, early_stop=True, xsim_thr=150.0, lambda_y=0.7, project=True, startpoint='none', mixup=True, precode_size=256, beta=0.001, aug_list='21-13-3+7-4-15', method='iid', TotalDevNum=10, DevNum=5, n_data=64)
Currently evaluating -------------------------------:
CPUs: 24, GPUs: 1 on ubuntu.
GPU : NVIDIA GeForce RTX 4090
Total images 64 on CIFAR10
Defense soteria against Attack gs on Dataset CIFAR10.
Sensitive_labels: tensor([5])
Proxy_labels: tensor([5])
Initial with CIFAR10
torch.Size([10, 512]) torch.Size([512])
0
torch.Size([64, 3, 7, 7])
1
torch.Size([64])
2
torch.Size([64])
3
torch.Size([64, 64, 3, 3])
4
torch.Size([64])
5
torch.Size([64])
6
torch.Size([64, 64, 3, 3])
7
torch.Size([64])
8
torch.Size([64])
9
torch.Size([64, 64, 3, 3])
10
torch.Size([64])
11
torch.Size([64])
12
torch.Size([64, 64, 3, 3])
13
torch.Size([64])
14
torch.Size([64])
15
torch.Size([128, 64, 3, 3])
16
torch.Size([128])
17
torch.Size([128])
18
torch.Size([128, 128, 3, 3])
19
torch.Size([128])
20
torch.Size([128])
21
torch.Size([128, 64, 1, 1])
22
torch.Size([128])
23
torch.Size([128])
24
torch.Size([128, 128, 3, 3])
25
torch.Size([128])
26
torch.Size([128])
27
torch.Size([128, 128, 3, 3])
28
torch.Size([128])
29
torch.Size([128])
30
torch.Size([256, 128, 3, 3])
31
torch.Size([256])
32
torch.Size([256])
33
torch.Size([256, 256, 3, 3])
34
torch.Size([256])
35
torch.Size([256])
36
torch.Size([256, 128, 1, 1])
37
torch.Size([256])
38
torch.Size([256])
39
torch.Size([256, 256, 3, 3])
40
torch.Size([256])
41
torch.Size([256])
42
torch.Size([256, 256, 3, 3])
43
torch.Size([256])
44
torch.Size([256])
45
torch.Size([512, 256, 3, 3])
46
torch.Size([512])
47
torch.Size([512])
48
torch.Size([512, 512, 3, 3])
49
torch.Size([512])
50
torch.Size([512])
51
torch.Size([512, 256, 1, 1])
52
torch.Size([512])
53
torch.Size([512])
54
torch.Size([512, 512, 3, 3])
55
torch.Size([512])
56
torch.Size([512])
57
torch.Size([512, 512, 3, 3])
58
torch.Size([512])
59
torch.Size([512])
60
torch.Size([10, 512])
61
torch.Size([10])
62
Finished defence with time: 0:00:24.763388
Attack - Iter-0: Rec_loss-0.4180.
Attack - Iter-1000: Rec_loss-0.1624.
Attack - Iter-2000: Rec_loss-0.1635.
Attack - Iter-3000: Rec_loss-0.1529.
Attack - Iter-4000: Rec_loss-0.1624.
Attack - Iter-5000: Rec_loss-0.1491.
Attack - Iter-6000: Rec_loss-0.1446.
Attack - Iter-7000: Rec_loss-0.1510.
Attack - Iter-8000: Rec_loss-0.1528.
Attack - Iter-9000: Rec_loss-0.1479.
Attack - Iter-9999: Rec_loss-0.1550.
PSNR 19.9914 SSIM 0.6144 LPIPS -0.0000
Tuesday, 29. October 2024 10:49PM
Finished computations with time: 0:02:35.587756
